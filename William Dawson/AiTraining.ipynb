{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hIaIiDJIlOH",
        "outputId": "a054ab44-55e0-4345-dcb2-79ff6062a86f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Folder already exists. Skipping unzip.\n",
            "['Benign cases', 'Normal cases', 'adenocarcinoma', 'large cell carcinoma', 'squamous cell carcinoma']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 77/77 [01:32<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 20/20 [00:29<00:00,  1.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.0838\n",
            "Validation: 72.3127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 77/77 [00:11<00:00,  6.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.7248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 20/20 [00:02<00:00,  8.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7248\n",
            "Validation: 75.8958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 77/77 [00:11<00:00,  6.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.5668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 20/20 [00:02<00:00,  7.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.5668\n",
            "Validation: 81.7590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 77/77 [00:10<00:00,  7.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.4297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 20/20 [00:02<00:00,  6.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4297\n",
            "Validation: 85.0163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 77/77 [00:10<00:00,  7.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 0.3302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 20/20 [00:03<00:00,  5.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3302\n",
            "Validation: 87.2964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from numpy import test\n",
        "from torch.jit import load\n",
        "from sklearn.utils import np\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "\n",
        "!pip install kaggle\n",
        "\n",
        "from google.colab import files, drive\n",
        "drive.mount('/content/drive')\n",
        "from zipfile import ZipFile\n",
        "\n",
        "zip_path = \"/content/archive.zip\"\n",
        "extract_dir = \"/content/drive/MyDrive/lung_cancer_data/Lung Cancer Dataset\"\n",
        "\n",
        "if not os.path.exists(extract_dir):\n",
        "    os.makedirs(os.path.dirname(extract_dir), exist_ok=True)\n",
        "    with ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"/content/drive/MyDrive/lung_cancer_data\")\n",
        "    print(\"Unzipped successfully!\")\n",
        "else:\n",
        "    print(\"Folder already exists. Skipping unzip.\")\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data = ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def get_classes(self):\n",
        "        return self.data.classes\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = ImageDataset(data_dir=extract_dir, transform=transform)\n",
        "print (dataset.get_classes())\n",
        "\n",
        "for image, label in dataset:\n",
        "    break\n",
        "\n",
        "num_classes = len(dataset.get_classes())\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, num_workers=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, num_workers=8, shuffle=False)\n",
        "\n",
        "class LungCancerModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(LungCancerModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding= 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding= 1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = LungCancerModel(num_classes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "num_epochs = 5\n",
        "\n",
        "train_loss_per = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    train_loss_per.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    val_loss_per = []\n",
        "\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=f\"Testing\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        val_loss = running_loss / len(test_loader.dataset)\n",
        "        val_loss_per.append(val_loss)\n",
        "\n",
        "        print(f\"Training Loss: {train_loss_per[-1]:.4f}\")\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Validation: {accuracy:.4f}\")\n"
      ]
    }
  ]
}